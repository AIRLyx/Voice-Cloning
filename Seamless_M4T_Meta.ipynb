{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNjxyAmC79bAGhIN2VBswTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinWang676/Bark-Voice-Cloning/blob/main/Seamless_M4T_Meta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Fg9Q8mUpY2",
        "outputId": "699816be-dbf7-4981-b0fa-e43b966b86b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'seamless-test'...\n",
            "remote: Enumerating objects: 60, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 60 (delta 13), reused 0 (delta 0), pack-reused 30\u001b[K\n",
            "Unpacking objects: 100% (60/60), 19.96 KiB | 1.25 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/spaces/kevinwang676/seamless-test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd seamless-test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGQBvR8gUt6q",
        "outputId": "93f34cf9-4958-474d-c683-c20a16b65142"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/seamless-test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP3emM0iUvDs",
        "outputId": "107d05f2-a68a-4d4e-b41b-091f83b281bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio (from -r requirements.txt (line 1))\n",
            "  Downloading gradio-4.9.0-py3-none-any.whl (16.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf==2.0.6 (from -r requirements.txt (line 2))\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Collecting fairseq (from -r requirements.txt (line 5))\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=5.1.* in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.0.6->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from omegaconf==2.0.6->-r requirements.txt (line 2)) (4.5.0)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.2 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading gradio_client-0.7.2-py3-none-any.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.6/304.6 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (0.19.4)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (6.1.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (1.23.5)\n",
            "Collecting orjson~=3.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (9.4.0)\n",
            "Collecting pydantic>=2.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 1)) (0.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 1))\n",
            "  Downloading uvicorn-0.24.0.post1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.7.2->gradio->-r requirements.txt (line 1)) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.7.2->gradio->-r requirements.txt (line 1))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 5)) (3.0.6)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->-r requirements.txt (line 5))\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 5)) (2023.6.3)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->-r requirements.txt (line 5))\n",
            "  Downloading sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 5)) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 5)) (4.66.1)\n",
            "Collecting bitarray (from fairseq->-r requirements.txt (line 5))\n",
            "  Downloading bitarray-2.8.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (285 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.3/285.3 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 5)) (2.1.0+cu118)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 1)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 1)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 1)) (0.12.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 1)) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 1)) (2.31.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->-r requirements.txt (line 5))\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 1)) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 1)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 1)) (2023.3.post1)\n",
            "Collecting annotated-types>=0.4.0 (from pydantic>=2.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
            "Collecting pydantic-core==2.14.5 (from pydantic>=2.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading pydantic_core-2.14.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions (from omegaconf==2.0.6->-r requirements.txt (line 2))\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 5))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 5)) (0.9.0)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 5))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 5)) (4.9.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->-r requirements.txt (line 5)) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->-r requirements.txt (line 5)) (2.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 1)) (8.1.7)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 1))\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 1)) (13.7.0)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 1))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->-r requirements.txt (line 5)) (2.21)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio->-r requirements.txt (line 1)) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 1))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 1)) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx->gradio->-r requirements.txt (line 1))\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 1)) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->gradio->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 1)) (23.1.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 1)) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 1)) (0.31.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->-r requirements.txt (line 1)) (0.13.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio->-r requirements.txt (line 1)) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 1)) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio->-r requirements.txt (line 1)) (2.0.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio->-r requirements.txt (line 1)) (0.1.2)\n",
            "Building wheels for collected packages: fairseq, antlr4-python3-runtime, ffmpy\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11291816 sha256=38aed7ff01d597a63a7d4742f071a8a748afbeeca13cda1d4a53455616d15e2e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=fa053a5b79ef6263a35260f1b199a0479bdf538f9f23b90bd5902890d59ae3e4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=574dc1f0575f55104d3b0ae75ad23ad9acc17126fa4d6bc22ac57a0d7792d00e\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built fairseq antlr4-python3-runtime ffmpy\n",
            "Installing collected packages: pydub, ffmpy, bitarray, antlr4-python3-runtime, websockets, typing-extensions, tomlkit, shellingham, semantic-version, python-multipart, portalocker, orjson, h11, colorama, annotated-types, aiofiles, uvicorn, starlette, sacrebleu, pydantic-core, omegaconf, httpcore, pydantic, hydra-core, httpx, gradio-client, fastapi, fairseq, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 1.10.13\n",
            "    Uninstalling pydantic-1.10.13:\n",
            "      Successfully uninstalled pydantic-1.10.13\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 annotated-types-0.6.0 antlr4-python3-runtime-4.8 bitarray-2.8.5 colorama-0.4.6 fairseq-0.12.2 fastapi-0.105.0 ffmpy-0.3.1 gradio-4.9.0 gradio-client-0.7.2 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 hydra-core-1.0.7 omegaconf-2.0.6 orjson-3.9.10 portalocker-2.8.2 pydantic-2.5.2 pydantic-core-2.14.5 pydub-0.25.1 python-multipart-0.0.6 sacrebleu-2.4.0 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.27.0 tomlkit-0.12.0 typing-extensions-4.9.0 uvicorn-0.24.0.post1 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install speechbrain\n",
        "!pip install scipy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGcLBt27o74O",
        "outputId": "16f98ba1-3d92-4a82-b614-971af135fb2b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting speechbrain\n",
            "  Downloading speechbrain-0.5.16-py3-none-any.whl (630 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m630.6/630.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperpyyaml (from speechbrain)\n",
            "  Downloading HyperPyYAML-1.2.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from speechbrain) (23.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from speechbrain) (1.11.4)\n",
            "Collecting sentencepiece (from speechbrain)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from speechbrain) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from speechbrain) (4.66.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from speechbrain) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->speechbrain) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->speechbrain) (6.0.1)\n",
            "Collecting ruamel.yaml>=0.17.28 (from hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.28->hyperpyyaml->speechbrain)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->speechbrain) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->speechbrain) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.9->speechbrain) (1.3.0)\n",
            "Installing collected packages: sentencepiece, ruamel.yaml.clib, ruamel.yaml, hyperpyyaml, speechbrain\n",
            "Successfully installed hyperpyyaml-1.2.2 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8 sentencepiece-0.1.99 speechbrain-0.5.16\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.11.4)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy) (1.23.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/facebookresearch/seamless_communication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvvskxcQmSCG",
        "outputId": "aa2cae24-d54c-45c9-ce4e-91544da0e6b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/seamless_communication\n",
            "  Cloning https://github.com/facebookresearch/seamless_communication to /tmp/pip-req-build-e6wy8l6g\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/seamless_communication /tmp/pip-req-build-e6wy8l6g\n",
            "  Resolved https://github.com/facebookresearch/seamless_communication to commit 58796ae18822d94c8315b420424dbfda8873455e\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting datasets (from seamless-communication==1.0.0)\n",
            "  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fairseq2==0.2.* (from seamless-communication==1.0.0)\n",
            "  Downloading fairseq2-0.2.0-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.8/191.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fire (from seamless-communication==1.0.0)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from seamless-communication==1.0.0) (0.10.1)\n",
            "Collecting openai-whisper (from seamless-communication==1.0.0)\n",
            "  Downloading openai-whisper-20231117.tar.gz (798 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m798.6/798.6 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torchvision==0.16.0+cu121 --extra-index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "id": "anulr4eRxZ8M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "\n",
        "import gradio as gr\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "from fairseq2.assets import InProcAssetMetadataProvider, asset_store\n",
        "from huggingface_hub import snapshot_download\n",
        "from seamless_communication.inference import Translator\n",
        "\n",
        "from lang_list import (\n",
        "    ASR_TARGET_LANGUAGE_NAMES,\n",
        "    LANGUAGE_NAME_TO_CODE,\n",
        "    S2ST_TARGET_LANGUAGE_NAMES,\n",
        "    S2TT_TARGET_LANGUAGE_NAMES,\n",
        "    T2ST_TARGET_LANGUAGE_NAMES,\n",
        "    T2TT_TARGET_LANGUAGE_NAMES,\n",
        "    TEXT_SOURCE_LANGUAGE_NAMES,\n",
        ")\n",
        "\n",
        "from scipy.io import wavfile\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "from speechbrain.pretrained import SpectralMaskEnhancement\n",
        "\n",
        "enhance_model = SpectralMaskEnhancement.from_hparams(\n",
        "    source=\"speechbrain/metricgan-plus-voicebank\",\n",
        "    savedir=\"pretrained_models/metricgan-plus-voicebank\",\n",
        ")\n",
        "\n",
        "knn_vc = torch.hub.load('bshall/knn-vc', 'knn_vc', prematched=True, trust_repo=True, pretrained=True, device='cpu')\n",
        "\n",
        "def voice_change(audio_in, audio_ref):\n",
        "    samplerate1, data1 = wavfile.read(audio_in)\n",
        "    samplerate2, data2 = wavfile.read(audio_ref)\n",
        "    write(\"./audio_in.wav\", samplerate1, data1)\n",
        "    write(\"./audio_ref.wav\", samplerate2, data2)\n",
        "\n",
        "    query_seq = knn_vc.get_features(\"./audio_in.wav\")\n",
        "    matching_set = knn_vc.get_matching_set([\"./audio_ref.wav\"])\n",
        "    out_wav = knn_vc.match(query_seq, matching_set, topk=4)\n",
        "    torchaudio.save('output.wav', out_wav[None], 16000)\n",
        "    noisy = enhance_model.load_audio(\n",
        "        'output.wav'\n",
        "    ).unsqueeze(0)\n",
        "    enhanced = enhance_model.enhance_batch(noisy, lengths=torch.tensor([1.]))\n",
        "    torchaudio.save('enhanced.wav', enhanced.cpu(), 16000)\n",
        "    return 'enhanced.wav'\n",
        "\n",
        "\n",
        "CHECKPOINTS_PATH = pathlib.Path(os.getenv(\"CHECKPOINTS_PATH\", \"/home/user/app/models\"))\n",
        "if not CHECKPOINTS_PATH.exists():\n",
        "    snapshot_download(repo_id=\"facebook/seamless-m4t-v2-large\", repo_type=\"model\", local_dir=CHECKPOINTS_PATH)\n",
        "asset_store.env_resolvers.clear()\n",
        "asset_store.env_resolvers.append(lambda: \"demo\")\n",
        "demo_metadata = [\n",
        "    {\n",
        "        \"name\": \"seamlessM4T_v2_large@demo\",\n",
        "        \"checkpoint\": f\"file://{CHECKPOINTS_PATH}/seamlessM4T_v2_large.pt\",\n",
        "        \"char_tokenizer\": f\"file://{CHECKPOINTS_PATH}/spm_char_lang38_tc.model\",\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"vocoder_v2@demo\",\n",
        "        \"checkpoint\": f\"file://{CHECKPOINTS_PATH}/vocoder_v2.pt\",\n",
        "    },\n",
        "]\n",
        "asset_store.metadata_providers.append(InProcAssetMetadataProvider(demo_metadata))\n",
        "\n",
        "DESCRIPTION = \"\"\"\\\n",
        "# SeamlessM4T\n",
        "[SeamlessM4T](https://github.com/facebookresearch/seamless_communication) is designed to provide high-quality\n",
        "translation, allowing people from different linguistic communities to communicate effortlessly through speech and text.\n",
        "This unified model enables multiple tasks like Speech-to-Speech (S2ST), Speech-to-Text (S2TT), Text-to-Speech (T2ST)\n",
        "translation and more, without relying on multiple separate models.\n",
        "\"\"\"\n",
        "\n",
        "CACHE_EXAMPLES = os.getenv(\"CACHE_EXAMPLES\") == \"1\" and torch.cuda.is_available()\n",
        "\n",
        "AUDIO_SAMPLE_RATE = 16000.0\n",
        "MAX_INPUT_AUDIO_LENGTH = 60  # in seconds\n",
        "DEFAULT_TARGET_LANGUAGE = \"French\"\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    dtype = torch.float16\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    dtype = torch.float32\n",
        "\n",
        "translator = Translator(\n",
        "    model_name_or_card=\"seamlessM4T_v2_large\",\n",
        "    vocoder_name_or_card=\"vocoder_v2\",\n",
        "    device=device,\n",
        "    dtype=dtype,\n",
        "    apply_mintox=True,\n",
        ")\n",
        "\n",
        "\n",
        "def preprocess_audio(input_audio: str) -> None:\n",
        "    arr, org_sr = torchaudio.load(input_audio)\n",
        "    new_arr = torchaudio.functional.resample(arr, orig_freq=org_sr, new_freq=AUDIO_SAMPLE_RATE)\n",
        "    max_length = int(MAX_INPUT_AUDIO_LENGTH * AUDIO_SAMPLE_RATE)\n",
        "    if new_arr.shape[1] > max_length:\n",
        "        new_arr = new_arr[:, :max_length]\n",
        "        gr.Warning(f\"Input audio is too long. Only the first {MAX_INPUT_AUDIO_LENGTH} seconds is used.\")\n",
        "    torchaudio.save(input_audio, new_arr, sample_rate=int(AUDIO_SAMPLE_RATE))\n",
        "\n",
        "\n",
        "def run_s2st(\n",
        "    input_audio: str, source_language: str, target_language: str\n",
        ") -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    preprocess_audio(input_audio)\n",
        "    source_language_code = LANGUAGE_NAME_TO_CODE[source_language]\n",
        "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
        "    out_texts, out_audios = translator.predict(\n",
        "        input=input_audio,\n",
        "        task_str=\"S2ST\",\n",
        "        src_lang=source_language_code,\n",
        "        tgt_lang=target_language_code,\n",
        "    )\n",
        "    out_text = str(out_texts[0])\n",
        "    out_wav = out_audios.audio_wavs[0].cpu().detach().numpy()\n",
        "    return (int(AUDIO_SAMPLE_RATE), out_wav), out_text\n",
        "\n",
        "\n",
        "def run_s2tt(input_audio: str, source_language: str, target_language: str) -> str:\n",
        "    preprocess_audio(input_audio)\n",
        "    source_language_code = LANGUAGE_NAME_TO_CODE[source_language]\n",
        "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
        "    out_texts, _ = translator.predict(\n",
        "        input=input_audio,\n",
        "        task_str=\"S2TT\",\n",
        "        src_lang=source_language_code,\n",
        "        tgt_lang=target_language_code,\n",
        "    )\n",
        "    return str(out_texts[0])\n",
        "\n",
        "\n",
        "def run_t2st(input_text: str, source_language: str, target_language: str) -> tuple[tuple[int, np.ndarray] | None, str]:\n",
        "    source_language_code = LANGUAGE_NAME_TO_CODE[source_language]\n",
        "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
        "    out_texts, out_audios = translator.predict(\n",
        "        input=input_text,\n",
        "        task_str=\"T2ST\",\n",
        "        src_lang=source_language_code,\n",
        "        tgt_lang=target_language_code,\n",
        "    )\n",
        "    out_text = str(out_texts[0])\n",
        "    out_wav = out_audios.audio_wavs[0].cpu().detach().numpy()\n",
        "    return (int(AUDIO_SAMPLE_RATE), out_wav), out_text\n",
        "\n",
        "\n",
        "def run_t2tt(input_text: str, source_language: str, target_language: str) -> str:\n",
        "    source_language_code = LANGUAGE_NAME_TO_CODE[source_language]\n",
        "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
        "    out_texts, _ = translator.predict(\n",
        "        input=input_text,\n",
        "        task_str=\"T2TT\",\n",
        "        src_lang=source_language_code,\n",
        "        tgt_lang=target_language_code,\n",
        "    )\n",
        "    return str(out_texts[0])\n",
        "\n",
        "\n",
        "def run_asr(input_audio: str, target_language: str) -> str:\n",
        "    preprocess_audio(input_audio)\n",
        "    target_language_code = LANGUAGE_NAME_TO_CODE[target_language]\n",
        "    out_texts, _ = translator.predict(\n",
        "        input=input_audio,\n",
        "        task_str=\"ASR\",\n",
        "        src_lang=target_language_code,\n",
        "        tgt_lang=target_language_code,\n",
        "    )\n",
        "    return str(out_texts[0])\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo_s2st:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Group():\n",
        "                input_audio = gr.Audio(label=\"请上传一段语音\", type=\"filepath\")\n",
        "                source_language = gr.Dropdown(\n",
        "                    label=\"请选择上传语音对应的语言\",\n",
        "                    choices=ASR_TARGET_LANGUAGE_NAMES,\n",
        "                    value=\"Mandarin Chinese\",\n",
        "                )\n",
        "                target_language = gr.Dropdown(\n",
        "                    label=\"请选择翻译后的语言\",\n",
        "                    choices=S2ST_TARGET_LANGUAGE_NAMES,\n",
        "                    value=\"English\",\n",
        "                )\n",
        "            btn = gr.Button(\"开始AI同声传译之旅吧\", variant=\"primary\")\n",
        "            btn_vc = gr.Button(\"恢复原本的音色吧！\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            with gr.Group():\n",
        "                output_audio = gr.Audio(\n",
        "                    label=\"同声传译后的语音\",\n",
        "                    autoplay=False,\n",
        "                    streaming=False,\n",
        "                    type=\"filepath\",\n",
        "                    interactive=False,\n",
        "                )\n",
        "                output_text = gr.Textbox(label=\"翻译后的文本\")\n",
        "                audio_vc = gr.Audio(\n",
        "                    label=\"相同音色的AI专属语音\",\n",
        "                    autoplay=False,\n",
        "                    streaming=False,\n",
        "                    type=\"filepath\",\n",
        "                )\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"assets/sample_input.mp3\", \"English\", \"French\"],\n",
        "            [\"assets/sample_input.mp3\", \"English\", \"Mandarin Chinese\"],\n",
        "            [\"assets/sample_input_2.mp3\", \"English\", \"Hindi\"],\n",
        "            [\"assets/sample_input_2.mp3\", \"English\", \"Spanish\"],\n",
        "        ],\n",
        "        inputs=[input_audio, source_language, target_language],\n",
        "        outputs=[output_audio, output_text],\n",
        "        fn=run_s2st,\n",
        "        cache_examples=CACHE_EXAMPLES,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    btn.click(\n",
        "        fn=run_s2st,\n",
        "        inputs=[input_audio, source_language, target_language],\n",
        "        outputs=[output_audio, output_text],\n",
        "        api_name=\"s2st\",\n",
        "    )\n",
        "    btn_vc.click(voice_change, [output_audio, input_audio], [audio_vc])\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo_s2tt:\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Group():\n",
        "                input_audio = gr.Audio(label=\"请上传一段语音\", type=\"filepath\")\n",
        "                source_language = gr.Dropdown(\n",
        "                    label=\"请选择上传语音对应的语言\",\n",
        "                    choices=ASR_TARGET_LANGUAGE_NAMES,\n",
        "                    value=\"Mandarin Chinese\",\n",
        "                )\n",
        "                target_language = gr.Dropdown(\n",
        "                    label=\"请选择翻译后的语言\",\n",
        "                    choices=S2TT_TARGET_LANGUAGE_NAMES,\n",
        "                    value=\"English\",\n",
        "                )\n",
        "            btn = gr.Button(\"开始AI翻译之旅吧！\")\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"翻译后的文本\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"assets/sample_input.mp3\", \"English\", \"French\"],\n",
        "            [\"assets/sample_input.mp3\", \"English\", \"Mandarin Chinese\"],\n",
        "            [\"assets/sample_input_2.mp3\", \"English\", \"Hindi\"],\n",
        "            [\"assets/sample_input_2.mp3\", \"English\", \"Spanish\"],\n",
        "        ],\n",
        "        inputs=[input_audio, source_language, target_language],\n",
        "        outputs=output_text,\n",
        "        fn=run_s2tt,\n",
        "        cache_examples=CACHE_EXAMPLES,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    btn.click(\n",
        "        fn=run_s2tt,\n",
        "        inputs=[input_audio, source_language, target_language],\n",
        "        outputs=output_text,\n",
        "        api_name=\"s2tt\",\n",
        "    )\n",
        "\n",
        "with gr.Blocks() as demo_t2st:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Group():\n",
        "                input_text = gr.Textbox(label=\"Input text\")\n",
        "                with gr.Row():\n",
        "                    source_language = gr.Dropdown(\n",
        "                        label=\"Source language\",\n",
        "                        choices=TEXT_SOURCE_LANGUAGE_NAMES,\n",
        "                        value=\"English\",\n",
        "                    )\n",
        "                    target_language = gr.Dropdown(\n",
        "                        label=\"Target language\",\n",
        "                        choices=T2ST_TARGET_LANGUAGE_NAMES,\n",
        "                        value=DEFAULT_TARGET_LANGUAGE,\n",
        "                    )\n",
        "            btn = gr.Button(\"Translate\")\n",
        "        with gr.Column():\n",
        "            with gr.Group():\n",
        "                output_audio = gr.Audio(\n",
        "                    label=\"Translated speech\",\n",
        "                    autoplay=False,\n",
        "                    streaming=False,\n",
        "                    type=\"numpy\",\n",
        "                )\n",
        "                output_text = gr.Textbox(label=\"Translated text\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\n",
        "                \"My favorite animal is the elephant.\",\n",
        "                \"English\",\n",
        "                \"French\",\n",
        "            ],\n",
        "            [\n",
        "                \"My favorite animal is the elephant.\",\n",
        "                \"English\",\n",
        "                \"Mandarin Chinese\",\n",
        "            ],\n",
        "            [\n",
        "                \"Meta AI's Seamless M4T model is democratising spoken communication across language barriers\",\n",
        "                \"English\",\n",
        "                \"Hindi\",\n",
        "            ],\n",
        "            [\n",
        "                \"Meta AI's Seamless M4T model is democratising spoken communication across language barriers\",\n",
        "                \"English\",\n",
        "                \"Spanish\",\n",
        "            ],\n",
        "        ],\n",
        "        inputs=[input_text, source_language, target_language],\n",
        "        outputs=[output_audio, output_text],\n",
        "        fn=run_t2st,\n",
        "        cache_examples=CACHE_EXAMPLES,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    gr.on(\n",
        "        triggers=[input_text.submit, btn.click],\n",
        "        fn=run_t2st,\n",
        "        inputs=[input_text, source_language, target_language],\n",
        "        outputs=[output_audio, output_text],\n",
        "        api_name=\"t2st\",\n",
        "    )\n",
        "\n",
        "with gr.Blocks() as demo_t2tt:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Group():\n",
        "                input_text = gr.Textbox(label=\"Input text\")\n",
        "                with gr.Row():\n",
        "                    source_language = gr.Dropdown(\n",
        "                        label=\"Source language\",\n",
        "                        choices=TEXT_SOURCE_LANGUAGE_NAMES,\n",
        "                        value=\"English\",\n",
        "                    )\n",
        "                    target_language = gr.Dropdown(\n",
        "                        label=\"Target language\",\n",
        "                        choices=T2TT_TARGET_LANGUAGE_NAMES,\n",
        "                        value=DEFAULT_TARGET_LANGUAGE,\n",
        "                    )\n",
        "            btn = gr.Button(\"Translate\")\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Translated text\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\n",
        "                \"My favorite animal is the elephant.\",\n",
        "                \"English\",\n",
        "                \"French\",\n",
        "            ],\n",
        "            [\n",
        "                \"My favorite animal is the elephant.\",\n",
        "                \"English\",\n",
        "                \"Mandarin Chinese\",\n",
        "            ],\n",
        "            [\n",
        "                \"Meta AI's Seamless M4T model is democratising spoken communication across language barriers\",\n",
        "                \"English\",\n",
        "                \"Hindi\",\n",
        "            ],\n",
        "            [\n",
        "                \"Meta AI's Seamless M4T model is democratising spoken communication across language barriers\",\n",
        "                \"English\",\n",
        "                \"Spanish\",\n",
        "            ],\n",
        "        ],\n",
        "        inputs=[input_text, source_language, target_language],\n",
        "        outputs=output_text,\n",
        "        fn=run_t2tt,\n",
        "        cache_examples=CACHE_EXAMPLES,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    gr.on(\n",
        "        triggers=[input_text.submit, btn.click],\n",
        "        fn=run_t2tt,\n",
        "        inputs=[input_text, source_language, target_language],\n",
        "        outputs=output_text,\n",
        "        api_name=\"t2tt\",\n",
        "    )\n",
        "\n",
        "with gr.Blocks() as demo_asr:\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            with gr.Group():\n",
        "                input_audio = gr.Audio(label=\"Input speech\", type=\"filepath\")\n",
        "                target_language = gr.Dropdown(\n",
        "                    label=\"Target language\",\n",
        "                    choices=ASR_TARGET_LANGUAGE_NAMES,\n",
        "                    value=DEFAULT_TARGET_LANGUAGE,\n",
        "                )\n",
        "            btn = gr.Button(\"Translate\")\n",
        "        with gr.Column():\n",
        "            output_text = gr.Textbox(label=\"Translated text\")\n",
        "\n",
        "    gr.Examples(\n",
        "        examples=[\n",
        "            [\"assets/sample_input.mp3\", \"English\"],\n",
        "            [\"assets/sample_input_2.mp3\", \"English\"],\n",
        "        ],\n",
        "        inputs=[input_audio, target_language],\n",
        "        outputs=output_text,\n",
        "        fn=run_asr,\n",
        "        cache_examples=CACHE_EXAMPLES,\n",
        "        api_name=False,\n",
        "    )\n",
        "\n",
        "    btn.click(\n",
        "        fn=run_asr,\n",
        "        inputs=[input_audio, target_language],\n",
        "        outputs=output_text,\n",
        "        api_name=\"asr\",\n",
        "    )\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "\n",
        "    gr.Markdown(\"# <center>🌊💕🎶 Meta AI 3秒同声传译 + 声音克隆</center>\")\n",
        "    gr.Markdown(\"## <center>🌟 - 只需3秒，用自己的声音说出百种语言，模型支持百种语言相互同传！ </center>\")\n",
        "    gr.Markdown(\"### <center>🍻 - 更多精彩应用，尽在[滔滔AI](http://www.talktalkai.com)；滔滔AI，为爱滔滔！💕</center>\")\n",
        "\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(label=\"S2ST\"):\n",
        "            demo_s2st.render()\n",
        "        with gr.Tab(label=\"S2TT\"):\n",
        "            demo_s2tt.render()\n",
        "        with gr.Tab(label=\"T2ST\"):\n",
        "            demo_t2st.render()\n",
        "        with gr.Tab(label=\"T2TT\"):\n",
        "            demo_t2tt.render()\n",
        "        with gr.Tab(label=\"ASR\"):\n",
        "            demo_asr.render()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.queue(max_size=50).launch(show_error=True, share=True)"
      ],
      "metadata": {
        "id": "UeEwvvlDU6OF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "swVy1EW0eoWf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}