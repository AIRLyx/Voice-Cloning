{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNz34mDemZJgVR01w0ZfJID",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1a1d75d3b054b2ea6908389b5cbe03a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d46fb9439a6b4b14b860bdf16108acbf",
              "IPY_MODEL_cac540084f9c48a09a2e1f575fa7d771",
              "IPY_MODEL_c37716576de94fe2a3a9db037233bfd2"
            ],
            "layout": "IPY_MODEL_47266bc71c88415bbc1a3bb56a447fee"
          }
        },
        "d46fb9439a6b4b14b860bdf16108acbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d29455e45a974e9194df96bcbaf54993",
            "placeholder": "​",
            "style": "IPY_MODEL_d0c6e19156df4dfda83ff9aa76a085c4",
            "value": "Downloading coarse_2.pt: 100%"
          }
        },
        "cac540084f9c48a09a2e1f575fa7d771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c7987c28ef647688ce8c320eaed890c",
            "max": 3934534533,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_296149a374b545de99fff107253b2fdc",
            "value": 3934534533
          }
        },
        "c37716576de94fe2a3a9db037233bfd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91defb5d2cf848aaa5e7b1825dc13977",
            "placeholder": "​",
            "style": "IPY_MODEL_e7e092a1c2574f46b6ccd136743eedba",
            "value": " 3.93G/3.93G [00:24&lt;00:00, 158MB/s]"
          }
        },
        "47266bc71c88415bbc1a3bb56a447fee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d29455e45a974e9194df96bcbaf54993": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c6e19156df4dfda83ff9aa76a085c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8c7987c28ef647688ce8c320eaed890c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "296149a374b545de99fff107253b2fdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "91defb5d2cf848aaa5e7b1825dc13977": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7e092a1c2574f46b6ccd136743eedba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5432969b914c4b33996039057137b494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_681416b5eace49bd927ea75c1fe75239",
              "IPY_MODEL_1b866c0cfe1f4673994ef6821ddd4a4d",
              "IPY_MODEL_c68f72e0a3224ae7b6d0bf81854a620c"
            ],
            "layout": "IPY_MODEL_f2fd79a1418c45179938865bd5f158c2"
          }
        },
        "681416b5eace49bd927ea75c1fe75239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be920fc8e5cb4dbb8282416df9b41328",
            "placeholder": "​",
            "style": "IPY_MODEL_0b141333b4504c56886e3f43b9ef792c",
            "value": "Downloading fine_2.pt: 100%"
          }
        },
        "1b866c0cfe1f4673994ef6821ddd4a4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70de854c5c524917abc8c2be20c1ac27",
            "max": 3741740229,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ee9ca6685ac461f8822bfa4746bf8ba",
            "value": 3741740229
          }
        },
        "c68f72e0a3224ae7b6d0bf81854a620c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7084b61f2744e8aad4915ac64ae5774",
            "placeholder": "​",
            "style": "IPY_MODEL_8a4d2f1486a24f3b93b3670f80ede5ef",
            "value": " 3.74G/3.74G [00:23&lt;00:00, 164MB/s]"
          }
        },
        "f2fd79a1418c45179938865bd5f158c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be920fc8e5cb4dbb8282416df9b41328": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b141333b4504c56886e3f43b9ef792c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70de854c5c524917abc8c2be20c1ac27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee9ca6685ac461f8822bfa4746bf8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7084b61f2744e8aad4915ac64ae5774": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a4d2f1486a24f3b93b3670f80ede5ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KevinWang676/Bark-Voice-Cloning/blob/main/Bark_Voice_Cloning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n281rhWYnEbf",
        "outputId": "7e309d03-72ad-4e52-c6a3-e5a104808127"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Bark-Voice-Cloning'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
            "remote: Compressing objects: 100% (29/29), done.\u001b[K\n",
            "remote: Total 102 (delta 12), reused 0 (delta 0), pack-reused 73\u001b[K\n",
            "Receiving objects: 100% (102/102), 204.59 KiB | 2.69 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/KevinWang676/Bark-Voice-Cloning.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Bark-Voice-Cloning/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyyMhQgBnJLG",
        "outputId": "041afb7b-79b5-4671-c655-1b3918d70575"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Bark-Voice-Cloning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fm8b-BXPnPDb",
        "outputId": "f1e401e7-d620-469b-db38-1eef313e0d8f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Ignoring fairseq: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Ignoring soundfile: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Collecting fairseq (from -r requirements.txt (line 1))\n",
            "  Downloading fairseq-0.12.2.tar.gz (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m52.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting audiolm-pytorch (from -r requirements.txt (line 3))\n",
            "  Downloading audiolm_pytorch-1.1.4-py3-none-any.whl (37 kB)\n",
            "Collecting gradio (from -r requirements.txt (line 4))\n",
            "  Downloading gradio-3.34.0-py3-none-any.whl (20.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting funcy (from -r requirements.txt (line 5))\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting linkify (from -r requirements.txt (line 6))\n",
            "  Downloading linkify-1.4.tar.gz (1.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mutagen (from -r requirements.txt (line 7))\n",
            "  Downloading mutagen-1.46.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytorch_seed (from -r requirements.txt (line 8))\n",
            "  Downloading pytorch_seed-0.2.0-py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (6.0)\n",
            "Collecting sentencepiece (from -r requirements.txt (line 10))\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sox (from -r requirements.txt (line 12))\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting transformers (from -r requirements.txt (line 13))\n",
            "  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m46.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 1)) (1.15.1)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 1)) (0.29.34)\n",
            "Collecting hydra-core<1.1,>=1.0.7 (from fairseq->-r requirements.txt (line 1))\n",
            "  Downloading hydra_core-1.0.7-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting omegaconf<2.1 (from fairseq->-r requirements.txt (line 1))\n",
            "  Downloading omegaconf-2.0.6-py3-none-any.whl (36 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 1)) (2022.10.31)\n",
            "Collecting sacrebleu>=1.4.12 (from fairseq->-r requirements.txt (line 1))\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 1)) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 1)) (4.65.0)\n",
            "Collecting bitarray (from fairseq->-r requirements.txt (line 1))\n",
            "  Downloading bitarray-2.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (273 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.8/273.8 kB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 1)) (2.0.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fairseq->-r requirements.txt (line 1)) (1.22.4)\n",
            "Collecting accelerate (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading accelerate-0.20.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/227.6 kB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting beartype (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.6.1 (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ema-pytorch>=0.2.2 (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading ema_pytorch-0.2.3-py3-none-any.whl (4.4 kB)\n",
            "Collecting encodec (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch->-r requirements.txt (line 3)) (1.2.0)\n",
            "Collecting lion-pytorch (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading lion_pytorch-0.1.2-py3-none-any.whl (4.4 kB)\n",
            "Collecting local-attention>=1.8.4 (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading local_attention-1.8.6-py3-none-any.whl (8.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from audiolm-pytorch->-r requirements.txt (line 3)) (1.2.2)\n",
            "Collecting vector-quantize-pytorch>=1.5.14 (from audiolm-pytorch->-r requirements.txt (line 3))\n",
            "  Downloading vector_quantize_pytorch-1.6.11-py3-none-any.whl (13 kB)\n",
            "Collecting aiofiles (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting aiohttp (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (4.2.2)\n",
            "Collecting fastapi (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading fastapi-0.97.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading ffmpy-0.3.0.tar.gz (4.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.6 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading gradio_client-0.2.6-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.3/288.3 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.2.0)\n",
            "Requirement already satisfied: markupsafe in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading orjson-3.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (8.4.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (1.10.7)\n",
            "Collecting pydub (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: pygments>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.14.0)\n",
            "Collecting python-multipart (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (2.27.1)\n",
            "Collecting semantic-version (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 4)) (4.5.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets>=10.0 (from gradio->-r requirements.txt (line 4))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (3.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 13)) (23.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers->-r requirements.txt (line 13))\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers->-r requirements.txt (line 13))\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 4)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 4)) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair>=4.2.0->gradio->-r requirements.txt (line 4)) (0.12.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client>=0.2.6->gradio->-r requirements.txt (line 4)) (2023.4.0)\n",
            "Collecting antlr4-python3-runtime==4.8 (from hydra-core<1.1,>=1.0.7->fairseq->-r requirements.txt (line 1))\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 4)) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 4))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->gradio->-r requirements.txt (line 4)) (2022.7.1)\n",
            "Collecting portalocker (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 1))\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 1)) (0.8.10)\n",
            "Collecting colorama (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 1))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.4.12->fairseq->-r requirements.txt (line 1)) (4.9.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->-r requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->-r requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->fairseq->-r requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq->-r requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->fairseq->-r requirements.txt (line 1)) (16.0.5)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 4)) (8.1.3)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.14.0->gradio->-r requirements.txt (line 4))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->audiolm-pytorch->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->gradio->-r requirements.txt (line 4)) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->gradio->-r requirements.txt (line 4))\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->gradio->-r requirements.txt (line 4))\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->gradio->-r requirements.txt (line 4))\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->gradio->-r requirements.txt (line 4))\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->gradio->-r requirements.txt (line 4))\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi->fairseq->-r requirements.txt (line 1)) (2.21)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio->-r requirements.txt (line 4))\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 4)) (2022.12.7)\n",
            "Collecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio->-r requirements.txt (line 4))\n",
            "  Downloading httpcore-0.17.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio->-r requirements.txt (line 4)) (3.0.9)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gradio->-r requirements.txt (line 4)) (1.26.15)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch->-r requirements.txt (line 3)) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->audiolm-pytorch->-r requirements.txt (line 3)) (3.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio->-r requirements.txt (line 4)) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio->-r requirements.txt (line 4)) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio->-r requirements.txt (line 4))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->gradio->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fairseq->-r requirements.txt (line 1)) (1.3.0)\n",
            "Building wheels for collected packages: fairseq, linkify, antlr4-python3-runtime, encodec, ffmpy\n",
            "  Building wheel for fairseq (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairseq: filename=fairseq-0.12.2-cp310-cp310-linux_x86_64.whl size=11170782 sha256=300885031b2ffd867c9da8ca40162af3e5699e35683391d682e67feeaa30eaa8\n",
            "  Stored in directory: /root/.cache/pip/wheels/e4/35/55/9c66f65ec7c83fd6fbc2b9502a0ac81b2448a1196159dacc32\n",
            "  Building wheel for linkify (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for linkify: filename=linkify-1.4-py3-none-any.whl size=2306 sha256=37074221b0f8a85e5e16d2b94fd3615a78103a9ace83554a45f85ecb2b27847c\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/31/9a/ed0c62727b209e92ddbef7adb699e0af0ef03d93ea10761efa\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141210 sha256=7e5d1e2b2362c7565790db7af0ebded55dec77586147c14ffbae76d7d527471e\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/20/bd/e1477d664f22d99989fd28ee1a43d6633dddb5cb9e801350d5\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45760 sha256=fca8508b36b0e27747f559dd272acb2b8b6188acabbd3a25fcc70d6729084c5f\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=bc25eb2faf30aa7c2434392d2ad0fd5d9cf2e584f773c96a28328ae23efd7a72\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built fairseq linkify antlr4-python3-runtime encodec ffmpy\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, pydub, linkify, funcy, ffmpy, bitarray, antlr4-python3-runtime, websockets, uc-micro-py, sox, semantic-version, python-multipart, portalocker, orjson, omegaconf, mutagen, multidict, h11, frozenlist, einops, colorama, beartype, async-timeout, aiofiles, yarl, uvicorn, starlette, sacrebleu, mdit-py-plugins, linkify-it-py, hydra-core, huggingface-hub, httpcore, aiosignal, transformers, httpx, fastapi, aiohttp, gradio-client, gradio, vector-quantize-pytorch, local-attention, lion-pytorch, fairseq, encodec, ema-pytorch, accelerate, pytorch_seed, audiolm-pytorch\n",
            "Successfully installed accelerate-0.20.3 aiofiles-23.1.0 aiohttp-3.8.4 aiosignal-1.3.1 antlr4-python3-runtime-4.8 async-timeout-4.0.2 audiolm-pytorch-1.1.4 beartype-0.14.1 bitarray-2.7.5 colorama-0.4.6 einops-0.6.1 ema-pytorch-0.2.3 encodec-0.1.1 fairseq-0.12.2 fastapi-0.97.0 ffmpy-0.3.0 frozenlist-1.3.3 funcy-2.0 gradio-3.34.0 gradio-client-0.2.6 h11-0.14.0 httpcore-0.17.2 httpx-0.24.1 huggingface-hub-0.15.1 hydra-core-1.0.7 linkify-1.4 linkify-it-py-2.0.2 lion-pytorch-0.1.2 local-attention-1.8.6 mdit-py-plugins-0.3.3 multidict-6.0.4 mutagen-1.46.0 omegaconf-2.0.6 orjson-3.9.1 portalocker-2.7.0 pydub-0.25.1 python-multipart-0.0.6 pytorch_seed-0.2.0 sacrebleu-2.3.1 safetensors-0.3.1 semantic-version-2.10.0 sentencepiece-0.1.99 sox-1.4.1 starlette-0.27.0 tokenizers-0.13.3 transformers-4.30.1 uc-micro-py-1.0.2 uvicorn-0.22.0 vector-quantize-pytorch-1.6.11 websockets-11.0.3 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cProfile import label\n",
        "import dataclasses\n",
        "from distutils.command.check import check\n",
        "from doctest import Example\n",
        "import gradio as gr\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import logging\n",
        "import torch\n",
        "import pytorch_seed\n",
        "import time\n",
        "\n",
        "from xml.sax import saxutils\n",
        "from bark.api import generate_with_settings\n",
        "from bark.api import save_as_prompt\n",
        "from util.settings import Settings\n",
        "#import nltk\n",
        "\n",
        "from bark import SAMPLE_RATE\n",
        "from cloning.clonevoice import clone_voice\n",
        "from bark.generation import SAMPLE_RATE, preload_models, _load_history_prompt, codec_decode\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "from util.parseinput import split_and_recombine_text, build_ssml, is_ssml, create_clips_from_ssml\n",
        "from datetime import datetime\n",
        "from tqdm.auto import tqdm\n",
        "from util.helper import create_filename, add_id3_tag\n",
        "from swap_voice import swap_voice_from_audio\n",
        "from training.training_prepare import prepare_semantics_from_text, prepare_wavs_from_semantics\n",
        "from training.train import training_prepare_files, train\n",
        "\n",
        "settings = Settings('config.yaml')\n",
        "\n",
        "\n",
        "def generate_text_to_speech(text, selected_speaker, text_temp, waveform_temp, eos_prob, quick_generation, complete_settings, seed, batchcount, progress=gr.Progress(track_tqdm=True)):\n",
        "    # Chunk the text into smaller pieces then combine the generated audio\n",
        "\n",
        "    # generation settings\n",
        "    if selected_speaker == 'None':\n",
        "        selected_speaker = None\n",
        "\n",
        "    voice_name = selected_speaker\n",
        "\n",
        "    if text == None or len(text) < 1:\n",
        "       if selected_speaker == None:\n",
        "            raise gr.Error('No text entered!')\n",
        "\n",
        "       # Extract audio data from speaker if no text and speaker selected\n",
        "       voicedata = _load_history_prompt(voice_name)\n",
        "       audio_arr = codec_decode(voicedata[\"fine_prompt\"])\n",
        "       result = create_filename(settings.output_folder_path, \"None\", \"extract\",\".wav\")\n",
        "       save_wav(audio_arr, result)\n",
        "       return result\n",
        "\n",
        "    if batchcount < 1:\n",
        "        batchcount = 1\n",
        "\n",
        "\n",
        "    silenceshort = np.zeros(int((float(settings.silence_sentence) / 1000.0) * SAMPLE_RATE), dtype=np.int16)  # quarter second of silence\n",
        "    silencelong = np.zeros(int((float(settings.silence_speakers) / 1000.0) * SAMPLE_RATE), dtype=np.float32)  # half a second of silence\n",
        "    use_last_generation_as_history = \"Use last generation as history\" in complete_settings\n",
        "    save_last_generation = \"Save generation as Voice\" in complete_settings\n",
        "    for l in range(batchcount):\n",
        "        currentseed = seed\n",
        "        if seed != None and seed > 2**32 - 1:\n",
        "            logger.warning(f\"Seed {seed} > 2**32 - 1 (max), setting to random\")\n",
        "            currentseed = None\n",
        "        if currentseed == None or currentseed <= 0:\n",
        "            currentseed = np.random.default_rng().integers(1, 2**32 - 1)\n",
        "        assert(0 < currentseed and currentseed < 2**32)\n",
        "\n",
        "        progress(0, desc=\"Generating\")\n",
        "\n",
        "        full_generation = None\n",
        "\n",
        "        all_parts = []\n",
        "        complete_text = \"\"\n",
        "        text = text.lstrip()\n",
        "        if is_ssml(text):\n",
        "            list_speak = create_clips_from_ssml(text)\n",
        "            prev_speaker = None\n",
        "            for i, clip in tqdm(enumerate(list_speak), total=len(list_speak)):\n",
        "                selected_speaker = clip[0]\n",
        "                # Add pause break between speakers\n",
        "                if i > 0 and selected_speaker != prev_speaker:\n",
        "                    all_parts += [silencelong.copy()]\n",
        "                prev_speaker = selected_speaker\n",
        "                text = clip[1]\n",
        "                text = saxutils.unescape(text)\n",
        "                if selected_speaker == \"None\":\n",
        "                    selected_speaker = None\n",
        "\n",
        "                print(f\"\\nGenerating Text ({i+1}/{len(list_speak)}) -> {selected_speaker} (Seed {currentseed}):`{text}`\")\n",
        "                complete_text += text\n",
        "                with pytorch_seed.SavedRNG(currentseed):\n",
        "                    audio_array = generate_with_settings(text_prompt=text, voice_name=selected_speaker, semantic_temp=text_temp, coarse_temp=waveform_temp, eos_p=eos_prob)\n",
        "                    currentseed = torch.random.initial_seed()\n",
        "                if len(list_speak) > 1:\n",
        "                    filename = create_filename(settings.output_folder_path, currentseed, \"audioclip\",\".wav\")\n",
        "                    save_wav(audio_array, filename)\n",
        "                    add_id3_tag(filename, text, selected_speaker, currentseed)\n",
        "\n",
        "                all_parts += [audio_array]\n",
        "        else:\n",
        "            texts = split_and_recombine_text(text, settings.input_text_desired_length, settings.input_text_max_length)\n",
        "            for i, text in tqdm(enumerate(texts), total=len(texts)):\n",
        "                print(f\"\\nGenerating Text ({i+1}/{len(texts)}) -> {selected_speaker} (Seed {currentseed}):`{text}`\")\n",
        "                complete_text += text\n",
        "                if quick_generation == True:\n",
        "                    with pytorch_seed.SavedRNG(currentseed):\n",
        "                        audio_array = generate_with_settings(text_prompt=text, voice_name=selected_speaker, semantic_temp=text_temp, coarse_temp=waveform_temp, eos_p=eos_prob)\n",
        "                        currentseed = torch.random.initial_seed()\n",
        "                else:\n",
        "                    full_output = use_last_generation_as_history or save_last_generation\n",
        "                    if full_output:\n",
        "                        full_generation, audio_array = generate_with_settings(text_prompt=text, voice_name=voice_name, semantic_temp=text_temp, coarse_temp=waveform_temp, eos_p=eos_prob, output_full=True)\n",
        "                    else:\n",
        "                        audio_array = generate_with_settings(text_prompt=text, voice_name=voice_name, semantic_temp=text_temp, coarse_temp=waveform_temp, eos_p=eos_prob)\n",
        "\n",
        "                # Noticed this in the HF Demo - convert to 16bit int -32767/32767 - most used audio format  \n",
        "                # audio_array = (audio_array * 32767).astype(np.int16)\n",
        "\n",
        "                if len(texts) > 1:\n",
        "                    filename = create_filename(settings.output_folder_path, currentseed, \"audioclip\",\".wav\")\n",
        "                    save_wav(audio_array, filename)\n",
        "                    add_id3_tag(filename, text, selected_speaker, currentseed)\n",
        "\n",
        "                if quick_generation == False and (save_last_generation == True or use_last_generation_as_history == True):\n",
        "                    # save to npz\n",
        "                    voice_name = create_filename(settings.output_folder_path, seed, \"audioclip\", \".npz\")\n",
        "                    save_as_prompt(voice_name, full_generation)\n",
        "                    if use_last_generation_as_history:\n",
        "                        selected_speaker = voice_name\n",
        "\n",
        "                all_parts += [audio_array]\n",
        "                # Add short pause between sentences\n",
        "                if text[-1] in \"!?.\\n\" and i > 1:\n",
        "                    all_parts += [silenceshort.copy()]\n",
        "\n",
        "        # save & play audio\n",
        "        result = create_filename(settings.output_folder_path, currentseed, \"final\",\".wav\")\n",
        "        save_wav(np.concatenate(all_parts), result)\n",
        "        # write id3 tag with text truncated to 60 chars, as a precaution...\n",
        "        add_id3_tag(result, complete_text, selected_speaker, currentseed)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "def save_wav(audio_array, filename):\n",
        "    write_wav(filename, SAMPLE_RATE, audio_array)\n",
        "\n",
        "def save_voice(filename, semantic_prompt, coarse_prompt, fine_prompt):\n",
        "    np.savez_compressed(\n",
        "        filename,\n",
        "        semantic_prompt=semantic_prompt,\n",
        "        coarse_prompt=coarse_prompt,\n",
        "        fine_prompt=fine_prompt\n",
        "    )\n",
        "    \n",
        "\n",
        "def on_quick_gen_changed(checkbox):\n",
        "    if checkbox == False:\n",
        "        return gr.CheckboxGroup.update(visible=True)\n",
        "    return gr.CheckboxGroup.update(visible=False)\n",
        "\n",
        "def delete_output_files(checkbox_state):\n",
        "    if checkbox_state:\n",
        "        outputs_folder = os.path.join(os.getcwd(), settings.output_folder_path)\n",
        "        if os.path.exists(outputs_folder):\n",
        "            purgedir(outputs_folder)\n",
        "    return False\n",
        "\n",
        "\n",
        "# https://stackoverflow.com/a/54494779\n",
        "def purgedir(parent):\n",
        "    for root, dirs, files in os.walk(parent):                                      \n",
        "        for item in files:\n",
        "            # Delete subordinate files                                                 \n",
        "            filespec = os.path.join(root, item)\n",
        "            os.unlink(filespec)\n",
        "        for item in dirs:\n",
        "            # Recursively perform this operation for subordinate directories   \n",
        "            purgedir(os.path.join(root, item))\n",
        "\n",
        "def convert_text_to_ssml(text, selected_speaker):\n",
        "    return build_ssml(text, selected_speaker)\n",
        "\n",
        "\n",
        "def training_prepare(selected_step, num_text_generations, progress=gr.Progress(track_tqdm=True)):\n",
        "    if selected_step == prepare_training_list[0]:\n",
        "        prepare_semantics_from_text()\n",
        "    else:\n",
        "        prepare_wavs_from_semantics()\n",
        "    return None\n",
        "\n",
        "\n",
        "def start_training(save_model_epoch, max_epochs, progress=gr.Progress(track_tqdm=True)):\n",
        "    training_prepare_files(\"./training/data/\", \"./training/data/checkpoint/hubert_base_ls960.pt\")\n",
        "    train(\"./training/data/\", save_model_epoch, max_epochs)\n",
        "    return None\n",
        "\n",
        "\n",
        "\n",
        "def apply_settings(themes, input_server_name, input_server_port, input_server_public, input_desired_len, input_max_len, input_silence_break, input_silence_speaker):\n",
        "    settings.selected_theme = themes\n",
        "    settings.server_name = input_server_name\n",
        "    settings.server_port = input_server_port\n",
        "    settings.server_share = input_server_public\n",
        "    settings.input_text_desired_length = input_desired_len\n",
        "    settings.input_text_max_length = input_max_len\n",
        "    settings.silence_sentence = input_silence_break\n",
        "    settings.silence_speaker = input_silence_speaker\n",
        "    settings.save()\n",
        "\n",
        "def restart():\n",
        "    global restart_server\n",
        "    restart_server = True\n",
        "\n",
        "\n",
        "def create_version_html():\n",
        "    python_version = \".\".join([str(x) for x in sys.version_info[0:3]])\n",
        "    versions_html = f\"\"\"\n",
        "python: <span title=\"{sys.version}\">{python_version}</span>\n",
        " • \n",
        "torch: {getattr(torch, '__long_version__',torch.__version__)}\n",
        " • \n",
        "gradio: {gr.__version__}\n",
        "\"\"\"\n",
        "    return versions_html\n",
        "\n",
        "    \n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "APPTITLE = \"Bark UI Enhanced v0.7\"\n",
        "\n",
        "\n",
        "autolaunch = False\n",
        "\n",
        "if len(sys.argv) > 1:\n",
        "    autolaunch = \"-autolaunch\" in sys.argv\n",
        "\n",
        "\n",
        "if torch.cuda.is_available() == False:\n",
        "    os.environ['BARK_FORCE_CPU'] = 'True'\n",
        "    logger.warning(\"No CUDA detected, fallback to CPU!\")\n",
        "\n",
        "print(f'smallmodels={os.environ.get(\"SUNO_USE_SMALL_MODELS\", False)}')\n",
        "print(f'enablemps={os.environ.get(\"SUNO_ENABLE_MPS\", False)}')\n",
        "print(f'offloadcpu={os.environ.get(\"SUNO_OFFLOAD_CPU\", False)}')\n",
        "print(f'forcecpu={os.environ.get(\"BARK_FORCE_CPU\", False)}')\n",
        "print(f'autolaunch={autolaunch}\\n\\n')\n",
        "\n",
        "#print(\"Updating nltk\\n\")\n",
        "#nltk.download('punkt')\n",
        "\n",
        "print(\"Preloading Models\\n\")\n",
        "preload_models()\n",
        "\n",
        "available_themes = [\"Default\", \"gradio/glass\", \"gradio/monochrome\", \"gradio/seafoam\", \"gradio/soft\", \"gstaff/xkcd\", \"freddyaboulton/dracula_revamped\", \"ysharma/steampunk\"]\n",
        "tokenizer_language_list = [\"de\",\"en\", \"pl\"]\n",
        "prepare_training_list = [\"Step 1: Semantics from Text\",\"Step 2: WAV from Semantics\"]\n",
        "\n",
        "seed = -1\n",
        "server_name = settings.server_name\n",
        "if len(server_name) < 1:\n",
        "    server_name = None\n",
        "server_port = settings.server_port\n",
        "if server_port <= 0:\n",
        "    server_port = None\n",
        "global run_server\n",
        "global restart_server\n",
        "\n",
        "run_server = True\n",
        "\n",
        "while run_server:\n",
        "    # Collect all existing speakers/voices in dir\n",
        "    speakers_list = []\n",
        "\n",
        "    for root, dirs, files in os.walk(\"./bark/assets/prompts\"):\n",
        "        for file in files:\n",
        "            if file.endswith(\".npz\"):\n",
        "                pathpart = root.replace(\"./bark/assets/prompts\", \"\")\n",
        "                name = os.path.join(pathpart, file[:-4])\n",
        "                if name.startswith(\"/\") or name.startswith(\"\\\\\"):\n",
        "                     name = name[1:]\n",
        "                speakers_list.append(name)\n",
        "\n",
        "    speakers_list = sorted(speakers_list, key=lambda x: x.lower())\n",
        "    speakers_list.insert(0, 'None')\n",
        "\n",
        "    print(f'Launching {APPTITLE} Server')\n",
        "\n",
        "    # Create Gradio Blocks\n",
        "\n",
        "    with gr.Blocks(title=f\"{APPTITLE}\", mode=f\"{APPTITLE}\", theme=settings.selected_theme) as barkgui:\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(f\"### [{APPTITLE}](https://github.com/C0untFloyd/bark-gui)\")\n",
        "            with gr.Column():\n",
        "                gr.HTML(create_version_html(), elem_id=\"versions\")\n",
        "\n",
        "        with gr.Tab(\"Clone Voice\"):\n",
        "            with gr.Row():\n",
        "                input_audio_filename = gr.Audio(label=\"Input audio.wav\", source=\"upload\", type=\"filepath\")\n",
        "            #transcription_text = gr.Textbox(label=\"Transcription Text\", lines=1, placeholder=\"Enter Text of your Audio Sample here...\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    initialname = \"/content/Bark-Voice-Cloning/bark/assets/prompts/file\"\n",
        "                    output_voice = gr.Textbox(label=\"Filename of trained Voice (do not change the initial name)\", lines=1, placeholder=initialname, value=initialname)\n",
        "                with gr.Column():\n",
        "                    tokenizerlang = gr.Dropdown(tokenizer_language_list, label=\"Base Language Tokenizer\", value=tokenizer_language_list[1])\n",
        "            with gr.Row():\n",
        "                clone_voice_button = gr.Button(\"Create Voice\")\n",
        "            with gr.Row():\n",
        "                dummy = gr.Text(label=\"Progress\")\n",
        "                npz_file = gr.File(label=\".npz file\")\n",
        "            speakers_list.insert(0, npz_file) # add prompt\n",
        "\n",
        "        with gr.Tab(\"TTS\"):\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    placeholder = \"Enter text here.\"\n",
        "                    input_text = gr.Textbox(label=\"Input Text\", lines=4, placeholder=placeholder)\n",
        "                with gr.Column():\n",
        "                        seedcomponent = gr.Number(label=\"Seed (default -1 = Random)\", precision=0, value=-1)\n",
        "                        batchcount = gr.Number(label=\"Batch count\", precision=0, value=1)\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    examples = [\n",
        "                        \"Special meanings: [laughter] [laughs] [sighs] [music] [gasps] [clears throat] MAN: WOMAN:\",\n",
        "                       \"♪ Never gonna make you cry, never gonna say goodbye, never gonna tell a lie and hurt you ♪\",\n",
        "                       \"And now — a picture of a larch [laughter]\",\n",
        "                       \"\"\"\n",
        "                            WOMAN: I would like an oatmilk latte please.\n",
        "                            MAN: Wow, that's expensive!\n",
        "                       \"\"\",\n",
        "                       \"\"\"<?xml version=\"1.0\"?>\n",
        "    <speak version=\"1.0\" xmlns=\"http://www.w3.org/2001/10/synthesis\"\n",
        "             xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\n",
        "             xsi:schemaLocation=\"http://www.w3.org/2001/10/synthesis\n",
        "                       http://www.w3.org/TR/speech-synthesis/synthesis.xsd\"\n",
        "             xml:lang=\"en-US\">\n",
        "    <voice name=\"/v2/en_speaker_9\">Look at that drunk guy!</voice>\n",
        "    <voice name=\"/v2/en_speaker_3\">Who is he?</voice>\n",
        "    <voice name=\"/v2/en_speaker_9\">WOMAN: [clears throat] 10 years ago, he proposed me and I rejected him.</voice>\n",
        "    <voice name=\"/v2/en_speaker_3\">Oh my God [laughs] he is still celebrating</voice>\n",
        "    </speak>\"\"\"\n",
        "                       ]\n",
        "                    examples = gr.Examples(examples=examples, inputs=input_text)\n",
        "                with gr.Column():\n",
        "                    convert_to_ssml_button = gr.Button(\"Convert Input Text to SSML\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    gr.Markdown(\"[Voice Prompt Library](https://suno-ai.notion.site/8b8e8749ed514b0cbf3f699013548683?v=bc67cff786b04b50b3ceb756fd05f68c)\")\n",
        "                    speaker = gr.Dropdown(speakers_list, value=speakers_list[0], label=\"Voice\")\n",
        "                    \n",
        "                with gr.Column():\n",
        "                    text_temp = gr.Slider(0.1, 1.0, value=0.6, label=\"Generation Temperature\", info=\"1.0 more diverse, 0.1 more conservative\")\n",
        "                    waveform_temp = gr.Slider(0.1, 1.0, value=0.7, label=\"Waveform temperature\", info=\"1.0 more diverse, 0.1 more conservative\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    quick_gen_checkbox = gr.Checkbox(label=\"Quick Generation\", value=True)\n",
        "                    settings_checkboxes = [\"Use last generation as history\", \"Save generation as Voice\"]\n",
        "                    complete_settings = gr.CheckboxGroup(choices=settings_checkboxes, value=settings_checkboxes, label=\"Detailed Generation Settings\", type=\"value\", interactive=True, visible=False)\n",
        "                with gr.Column():\n",
        "                    eos_prob = gr.Slider(0.0, 0.5, value=0.05, label=\"End of sentence probability\")\n",
        "\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    tts_create_button = gr.Button(\"Generate\")\n",
        "                with gr.Column():\n",
        "                    hidden_checkbox = gr.Checkbox(visible=False)\n",
        "                    button_stop_generation = gr.Button(\"Stop generation\")\n",
        "            with gr.Row():\n",
        "                output_audio = gr.Audio(label=\"Generated Audio\", type=\"filepath\")\n",
        "\n",
        "        with gr.Tab(\"Swap Voice\"):\n",
        "            with gr.Row():\n",
        "                 swap_audio_filename = gr.Audio(label=\"Input audio.wav to swap voice\", source=\"upload\", type=\"filepath\")\n",
        "            with gr.Row():\n",
        "                 with gr.Column():\n",
        "                     swap_tokenizer_lang = gr.Dropdown(tokenizer_language_list, label=\"Base Language Tokenizer\", value=tokenizer_language_list[1])\n",
        "                     swap_seed = gr.Number(label=\"Seed (default -1 = Random)\", precision=0, value=-1)\n",
        "                 with gr.Column():\n",
        "                     speaker_swap = gr.Dropdown(speakers_list, value=speakers_list[0], label=\"Voice\")\n",
        "                     swap_batchcount = gr.Number(label=\"Batch count\", precision=0, value=1)\n",
        "            with gr.Row():\n",
        "                swap_voice_button = gr.Button(\"Swap Voice\")\n",
        "            with gr.Row():\n",
        "                output_swap = gr.Audio(label=\"Generated Audio\", type=\"filepath\")\n",
        "\n",
        "        with gr.Tab(\"Training Data Prepare\"):\n",
        "            gr.Markdown(\"This tab should be used to generate the training dataset. For Step 1 put some books into the inputtext folder in UTF-8 Text Format.\")\n",
        "            prepare_semantics_number = gr.Number(label=\"Number of semantics to create\", precision=0, value=3079)\n",
        "            prepare_dropdown = gr.Dropdown(prepare_training_list, value=prepare_training_list[0], label=\"Prepare\")\n",
        "            training_prepare_button = gr.Button(\"Generate\")\n",
        "            dummytrd = gr.Text(label=\"Progress\")\n",
        "\n",
        "        with gr.Tab(\"Training\"):\n",
        "            with gr.Row():\n",
        "                gr.Markdown(\"This tab is used to train the actual model (language).\")\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    save_model_epoch = gr.Number(label=\"Auto-save model after number of epochs\", precision=0, value=1)\n",
        "                with gr.Column():\n",
        "                    max_epochs = gr.Number(label=\"Train for number of epochs\", precision=0, value=6)\n",
        "            with gr.Row():\n",
        "                with gr.Column():\n",
        "                    allowed_chars = ' abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789!@#$%^&*()-_+=\\\"\\':;[]{}/<>,.`~'\n",
        "                    allowedcharsfilter = gr.Textbox(label=\"Allowed chars for text input\", lines=1, value=allowed_chars)\n",
        "                with gr.Column():\n",
        "                    train_button = gr.Button(\"Start Training\")\n",
        "            with gr.Row():\n",
        "                dummytrain = gr.Text(label=\"Progress\")\n",
        "\n",
        "\n",
        "        with gr.Tab(\"Settings\"):\n",
        "            with gr.Row():\n",
        "                themes = gr.Dropdown(available_themes, label=\"Theme\", info=\"Change needs complete restart\", value=settings.selected_theme)\n",
        "            with gr.Row():\n",
        "                input_server_name = gr.Textbox(label=\"Server Name\", lines=1, info=\"Leave blank to run locally\", value=settings.server_name)\n",
        "                input_server_port = gr.Number(label=\"Server Port\", precision=0, info=\"Leave at 0 to use default\", value=settings.server_port)\n",
        "                share_checkbox = gr.Checkbox(label=\"Public Server\", value=settings.server_share)\n",
        "            with gr.Row():\n",
        "                input_desired_len = gr.Slider(100, 150, value=settings.input_text_desired_length, label=\"Desired Input Text Length\", info=\"Ideal length to split input sentences\")\n",
        "                input_max_len = gr.Slider(150, 256, value=settings.input_text_max_length, label=\"Max Input Text Length\", info=\"Maximum Input Text Length\")\n",
        "            with gr.Row():\n",
        "                input_silence_break = gr.Slider(1, 1000, value=settings.silence_sentence, label=\"Sentence Pause Time (ms)\", info=\"Silence between sentences in milliseconds\")\n",
        "                input_silence_speakers = gr.Slider(1, 5000, value=settings.silence_speakers, label=\"Speaker Pause Time (ms)\", info=\"Silence between different speakers in milliseconds\")\n",
        "\n",
        "            with gr.Row():\n",
        "                button_apply_settings = gr.Button(\"Apply Settings\")\n",
        "                button_apply_restart = gr.Button(\"Restart Server\")\n",
        "                button_delete_files = gr.Button(\"Clear output folder\")\n",
        "\n",
        "        quick_gen_checkbox.change(fn=on_quick_gen_changed, inputs=quick_gen_checkbox, outputs=complete_settings)\n",
        "        convert_to_ssml_button.click(convert_text_to_ssml, inputs=[input_text, speaker],outputs=input_text)\n",
        "        gen_click = tts_create_button.click(generate_text_to_speech, inputs=[input_text, speaker, text_temp, waveform_temp, eos_prob, quick_gen_checkbox, complete_settings, seedcomponent, batchcount],outputs=output_audio)\n",
        "        button_stop_generation.click(fn=None, inputs=None, outputs=None, cancels=[gen_click])\n",
        "        \n",
        "        # Javascript hack to display modal confirmation dialog\n",
        "        js = \"(x) => confirm('Are you sure? This will remove all files from output folder')\"\n",
        "        button_delete_files.click(None, None, hidden_checkbox, _js=js)\n",
        "        hidden_checkbox.change(delete_output_files, [hidden_checkbox], [hidden_checkbox])\n",
        "\n",
        "        swap_voice_button.click(swap_voice_from_audio, inputs=[swap_audio_filename, speaker_swap, swap_tokenizer_lang, swap_seed, swap_batchcount], outputs=output_swap)\n",
        "        clone_voice_button.click(clone_voice, inputs=[input_audio_filename, output_voice], outputs=[dummy, npz_file])\n",
        "        training_prepare_button.click(training_prepare, inputs=[prepare_dropdown, prepare_semantics_number], outputs=dummytrd)\n",
        "        train_button.click(start_training, inputs=[save_model_epoch, max_epochs], outputs=dummytrain)\n",
        "        button_apply_settings.click(apply_settings, inputs=[themes, input_server_name, input_server_port, share_checkbox, input_desired_len, input_max_len, input_silence_break, input_silence_speakers])\n",
        "        button_apply_restart.click(restart)\n",
        "\n",
        "        restart_server = False\n",
        "        try:\n",
        "            barkgui.queue().launch(show_error=True)\n",
        "        except:\n",
        "            restart_server = True\n",
        "            run_server = False\n",
        "        try:\n",
        "            while restart_server == False:\n",
        "                time.sleep(1.0)\n",
        "        except (KeyboardInterrupt, OSError):\n",
        "            print(\"Keyboard interruption in main thread... closing server.\")\n",
        "            run_server = False\n",
        "        barkgui.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312,
          "referenced_widgets": [
            "c1a1d75d3b054b2ea6908389b5cbe03a",
            "d46fb9439a6b4b14b860bdf16108acbf",
            "cac540084f9c48a09a2e1f575fa7d771",
            "c37716576de94fe2a3a9db037233bfd2",
            "47266bc71c88415bbc1a3bb56a447fee",
            "d29455e45a974e9194df96bcbaf54993",
            "d0c6e19156df4dfda83ff9aa76a085c4",
            "8c7987c28ef647688ce8c320eaed890c",
            "296149a374b545de99fff107253b2fdc",
            "91defb5d2cf848aaa5e7b1825dc13977",
            "e7e092a1c2574f46b6ccd136743eedba",
            "5432969b914c4b33996039057137b494",
            "681416b5eace49bd927ea75c1fe75239",
            "1b866c0cfe1f4673994ef6821ddd4a4d",
            "c68f72e0a3224ae7b6d0bf81854a620c",
            "f2fd79a1418c45179938865bd5f158c2",
            "be920fc8e5cb4dbb8282416df9b41328",
            "0b141333b4504c56886e3f43b9ef792c",
            "70de854c5c524917abc8c2be20c1ac27",
            "2ee9ca6685ac461f8822bfa4746bf8ba",
            "b7084b61f2744e8aad4915ac64ae5774",
            "8a4d2f1486a24f3b93b3670f80ede5ef"
          ]
        },
        "id": "jDsXfOlEnTO-",
        "outputId": "abd7ec3f-21cd-4dd9-ffa0-54eb7e01663c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "smallmodels=False\n",
            "enablemps=False\n",
            "offloadcpu=False\n",
            "forcecpu=False\n",
            "autolaunch=False\n",
            "\n",
            "\n",
            "Preloading Models\n",
            "\n",
            "Downloading coarse suno/bark remote model file https://huggingface.co/suno/bark/resolve/main/coarse_2.pt coarse_2.pt to ./models\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading coarse_2.pt:   0%|          | 0.00/3.93G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1a1d75d3b054b2ea6908389b5cbe03a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading coarse model from ./models/coarse_2.pt to cuda\n",
            "Downloading fine suno/bark remote model file https://huggingface.co/suno/bark/resolve/main/fine_2.pt fine_2.pt to ./models\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading fine_2.pt:   0%|          | 0.00/3.74G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5432969b914c4b33996039057137b494"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fine model from ./models/fine_2.pt to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Mt5lkF1gnX54"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}